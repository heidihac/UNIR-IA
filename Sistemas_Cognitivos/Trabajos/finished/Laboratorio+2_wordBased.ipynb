{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mX8gZlVyCCbz"
   },
   "source": [
    "# Laboratorio: Modelos del lenguaje con RNNs\n",
    "\n",
    "En este laboratorio, vamos a entrenar un modelo del lenguaje basado en caracteres con Recurrent Neural Networks. Asimismo, utilizaremos el modelo para generar texto. En particular, alimentaremos nuestro modelo con obras de la literatura clásica en castellano para obtener una red neuronal que sea capaz de \"escribir\" fragmentos literarios.\n",
    "\n",
    "Los entrenamientos en esta laboratorio para obtener un modelo de calidad podrían tomar cierto tiempo (5-10 minutos por epoch), por lo que se aconseja empezar a trabajar pronto. El uso de GPUs no ayuda tanto con LSTMs como con CNNs, por lo que si tenéis máquinas potentes en casa es posible que podáis entrenar más rápido o a la misma velocidad que en Colab. En todo caso, la potencia de Colab es más que suficiente para completar este laboratorio con éxito.\n",
    "\n",
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/d/d8/El_ingenioso_hidalgo_don_Quijote_de_la_Mancha.jpg\" style=\"text-align: center\" height=\"300px\"></center>\n",
    "\n",
    "El dataset a utilizar consistirá en un archivo de texto con el contenido íntegro en castellano antiguo de El Ingenioso Hidalgo Don Quijote de la Mancha, disponible de manera libre en la página de [Project Gutenberg](https://www.gutenberg.org). Asimismo, como apartado optativo en este laboratorio se pueden utilizar otras fuentes de texto. Aquí podéis descargar los datos a utilizar de El Quijote y un par de obras adicionales:\n",
    "\n",
    "[El ingenioso hidalgo Don Quijote de la Mancha (Miguel de Cervantes)](https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219424&authkey=AH0gb-qSo5Xd7Io)\n",
    "\n",
    "[Compilación de obras teatrales (Calderón de la Barca)](https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219433&authkey=AKvGD6DC3IRBqmc)\n",
    "\n",
    "[Trafalgar (Benito Pérez Galdós)](https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219434&authkey=AErPCAtMKOI5tYQ)\n",
    "\n",
    "Como ya deberíamos de estar acostumbrados en problemas de Machine Learning, es importante echar un vistazo a los datos antes de empezar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QI274F8LQC59"
   },
   "source": [
    "## 1. Carga y procesado del texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZNnzvXuqVVm"
   },
   "source": [
    "Primero, vamos a descargar el libro e inspeccionar los datos. El fichero a descargar es una versión en .txt del libro de Don Quijote, a la cual se le han borrado introducciones, licencias y otras secciones para dejarlo con el contenido real de la novela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "D7tKOZ9BFfki"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import random\n",
    "import io\n",
    "\n",
    "path = keras.utils.get_file(\n",
    "    fname=\"don_quijote.txt\", \n",
    "    origin=\"https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219424&authkey=AH0gb-qSo5Xd7Io\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VYGLvjLXrUUd"
   },
   "source": [
    "Una vez descargado, vamos a leer el contenido del fichero en una variable. Adicionalmente, convertiremos el contenido del texto a minúsculas para ponérselo un poco más fácil a nuestro modelo (de modo que todas las letras sean minúsculas y el modelo no necesite diferenciar entre minúsculas y mayúsculas).\n",
    "\n",
    "**1.1.** Leer todo el contenido del fichero en una única variable ***text*** y convertir el string a minúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8WB6FejrrTu9"
   },
   "outputs": [],
   "source": [
    "text = open(path,encoding='UTF-8').read().lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dkgGl8GWtUk8"
   },
   "source": [
    "Podemos comprobar ahora que efectivamente nuestra variable contiene el resultado deseado, con el comienzo tan característico del Quijote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "hMFhe3COFwSD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del texto: 2071198\n",
      "capítulo primero. que trata de la condición y ejercicio del famoso hidalgo\n",
      "don quijote de la mancha\n",
      "\n",
      "\n",
      "en un lugar de la mancha, de cuyo nombre no quiero acordarme, no ha mucho\n",
      "tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua,\n",
      "rocín flaco y galgo corredor. una olla de algo más\n"
     ]
    }
   ],
   "source": [
    "print(\"Longitud del texto: {}\".format(len(text)))\n",
    "print(text[0:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = text[0:300]\n",
    "text = text[300:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZ7TUXWiyvOj"
   },
   "source": [
    "## 2. Procesado de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x66_Vi_Gyxns"
   },
   "source": [
    "Una de las grandes ventajas de trabajar con modelos que utilizan caracteres en vez de palabras es que no necesitamos tokenizar el texto (partirlo palabra a palabra). Nuestro modelo funcionará directamente con los caracteres en el texto, incluyendo espacios, saltos de línea, etc.\n",
    "\n",
    "Antes de hacer nada, necesitamos procesar el texto en entradas y salidas compatibles con nuestro modelo. Como sabemos, un modelo del lenguaje con RNNs acepta una serie de caracteres y predice el siguiente carácter en la secuencia.\n",
    "\n",
    "* \"*El ingenioso don Qui*\" -> predicción: **j**\n",
    "* \"*El ingenioso don Quij*\" -> predicción: **o**\n",
    "\n",
    "De modo que la entrada y la salida de nuestro modelo necesita ser algo parecido a este esquema. En este punto, podríamos usar dos formas de preparar los datos para nuestro modelo.\n",
    "\n",
    "1. **Secuencia a secuencia**. La entrada de nuestro modelo sería una secuencia y la salida sería esa secuencia trasladada un caracter a la derecha, de modo que en cada instante de tiempo la RNN tiene que predecir el carácter siguiente. Por ejemplo:\n",
    "\n",
    ">* *Input*:   El ingenioso don Quijot \n",
    ">* *Output*: l ingenioso don Quijote\n",
    "\n",
    "2. **Secuencia a carácter**. En este variante, pasaríamos una secuencia de caracteres por nuestra RNN y, al llegar al final de la secuencia, predeciríamos el siguiente carácter.\n",
    "\n",
    ">* *Input*:   El ingenioso don Quijot \n",
    ">* *Output*: e\n",
    "\n",
    "En este laboratorio, por simplicidad, vamos a utilizar la segunda variante.\n",
    "\n",
    "De este modo, a partir del texto, hemos de generar nuestro propio training data que consista en secuencias de caracteres con el siguiente carácter a predecir. Para estandarizar las cosas, utilizaremos secuencias de tamaño *SEQ_LENGTH* caracteres (un hiperparámetro que podemos elegir nosotros).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mkfJUIxW5m5C"
   },
   "source": [
    "#### 2.1. Obtención de los caracteres y mapas de caracteres\n",
    "\n",
    "Antes que nada, necesitamos saber qué caracteres aparecen en el texto, ya que tendremos que diferenciarlos mediante un índice de 0 a *num_chars* - 1 en el modelo. Obtener:\n",
    " \n",
    "\n",
    "1.   Número de caracteres únicos que aparecen en el texto.\n",
    "2.   Diccionario que asocia char a índice único entre 0 y *num_chars* - 1. Por ejemplo, {'a': 0, 'b': 1, ...}\n",
    "3.   Diccionario reverso de índices a caracteres: {0: 'a', 1: 'b', ...}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5bJ0NsbCbupF"
   },
   "outputs": [],
   "source": [
    "unique_characters = set()\n",
    "for sequence in text:\n",
    "    for character in sequence:\n",
    "        unique_characters.add(character)\n",
    "        \n",
    "\n",
    "ids = range(len(unique_characters))\n",
    "char_index_dict = dict(zip(unique_characters, list(ids)))\n",
    "index_char_dict = dict(zip(list(ids),unique_characters))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y_B4AWo0ElwA"
   },
   "source": [
    "#### 2.2. Obtención de secuencias de entrada y carácter a predecir\n",
    "\n",
    "Ahora, vamos a obtener las secuencias de entrada en formato texto y los correspondientes caracteres a predecir. Para ello, recorrer el texto completo leído anteriormente, obteniendo una secuencia de SEQ_LENGTH caracteres y el siguiente caracter a predecir. Una vez hecho, desplazarse un carácter a la izquierda y hacer lo mismo para obtener una nueva secuencia y predicción. Guardar las secuencias en una variable ***sequences*** y los caracteres a predecir en una variable ***next_chars***.\n",
    "\n",
    "Por ejemplo, si el texto fuera \"Don Quijote\" y SEQ_LENGTH fuese 5, tendríamos\n",
    "\n",
    "* *sequences* = [\"Don Q\", \"on Qu\", \"n Qui\", \" Quij\", \"Quijo\", \"uijot\"]\n",
    "* *next_chars* = ['u', 'i', 'j', 'o', 't', 'e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "NslxhnnDK6uA"
   },
   "outputs": [],
   "source": [
    "# Definimos el tamaño de las secuencias. Puedes dejar este valor por defecto.\n",
    "SEQ_LENGTH = 30\n",
    "\n",
    "sequences = []\n",
    "next_chars = []\n",
    "\n",
    "# NOTE: is this a bug? But full_sequence has to be 31 of length, not 30!\n",
    "full_sequence = [text[i:i+j+1] for i in range(len(text)-SEQ_LENGTH) for j in range(SEQ_LENGTH,SEQ_LENGTH+1)]\n",
    "\n",
    "for sequence in full_sequence:\n",
    "    sequences.append(sequence[:-1])\n",
    "    next_chars.append(sequence[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Y3AmjYtHdLJ"
   },
   "source": [
    "Indicar el tamaño del training set que acabamos de generar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "WVWqKxFcbwTu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2070868"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "goGQkKcwpLRJ"
   },
   "source": [
    "Como el Quijote es muy largo y tenemos muchas secuencias, podríamos encontrar problemas de memoria. Por ello, vamos a elegir un número máximo de ellas. Si estás corriendo esto localmente y tienes problemas de memoria, puedes reducir el tamaño aún más, pero ten cuidado porque, a menos datos, peor calidad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "2pm1Q19ppw8F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCES = len(sequences)\n",
    "MAX_SEQUENCES = 500000\n",
    "MAX_SEQUENCES = 100000\n",
    "#MAX_SEQUENCES = 500\n",
    "\n",
    "perm = np.random.permutation(len(sequences))\n",
    "sequences_short, next_chars_short = np.array(sequences), np.array(next_chars)\n",
    "sequences_short, next_chars_short = sequences_short[perm], next_chars_short[perm]\n",
    "sequences_short, next_chars_short = list(sequences_short[:MAX_SEQUENCES]), list(next_chars_short[:MAX_SEQUENCES])\n",
    "\n",
    "print(len(sequences_short))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4FzgtAbPIs6f"
   },
   "source": [
    "#### 2.3. Obtención de input X y output y para el modelo\n",
    "\n",
    "Finalmente, a partir de los datos de entrenamiento que hemos generado vamos a crear los arrays de datos X e y que pasaremos a nuestro modelo.\n",
    "\n",
    "Para ello, vamos a utilizar *one-hot encoding* para nuestros caracteres. Por ejemplo, si sólo tuviéramos 4 caracteres (a, b, c, d), las representaciones serían: (1, 0, 0, 0), (0, 1, 0, 0), (0, 0, 1, 0) y (0, 0, 0, 1).\n",
    "\n",
    "De este modo, **X** tendrá shape *(num_sequences, seq_length, num_chars)* e  **y**  tendrá shape _(num_sequences, num_chars)_. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "zMBwZ9obNGNg"
   },
   "outputs": [],
   "source": [
    "NUM_CHARS = len(unique_characters)  # Tu número de caracteres distintos aquí\n",
    "NUM_SEQUENCES = len(sequences_short)\n",
    "X = np.zeros((NUM_SEQUENCES, SEQ_LENGTH, NUM_CHARS))\n",
    "y = np.zeros((NUM_SEQUENCES, NUM_CHARS))\n",
    "\n",
    "\n",
    "## Tu código para rellenar X e y aquí. Pista: utilizar el diccionario de\n",
    "## chars a índices obtenido anteriormente junto con numpy. Por ejemplo,\n",
    "## si hacemos \n",
    "##     X[0, 1, char_to_indices['a']] = 1\n",
    "## estamos diciendo que para la segunda posición de la primera secuencia se\n",
    "## tiene una 'a'\n",
    "\n",
    "# Map each unique character to a one hot encoded array\n",
    "one_hot = to_categorical(ids)\n",
    "char_one_hot_dict = dict(zip(unique_characters, list(one_hot)))\n",
    "\n",
    "for i, character in enumerate(next_chars_short):\n",
    "    y[i] = char_one_hot_dict[character]\n",
    "    \n",
    "for i, sequence in enumerate(sequences_short):\n",
    "    for j, character in enumerate(sequence):\n",
    "        X[i][j] = char_one_hot_dict[character]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_text(text, encoding):\n",
    "    \"\"\"\n",
    "    Helper function that encodes given text using encoding (like embedding)\n",
    "    \"\"\"\n",
    "    enc = []\n",
    "    for i, char in enumerate(text):\n",
    "        enc.append(encoding[char])\n",
    "    return np.array(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_text(sequences_short[0], char_one_hot_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxeUxz3HPm3l"
   },
   "source": [
    "## 3. Definición del modelo y entrenamiento\n",
    "\n",
    "Una vez tenemos ya todo preparado, es hora de definir el modelo. Define un modelo que utilice una **LSTM** con **128 unidades internas**. Si bien el modelo puede definirse de una manera más compleja, para empezar debería bastar con una LSTM más una capa Dense con el *softmax* que predice el siguiente caracter a producir. Adam puede ser una buena elección de optimizador.\n",
    "\n",
    "Una vez el modelo esté definido, entrénalo un poco para asegurarte de que la loss es decreciente. No es necesario guardar la salida de este entrenamiento en el entregable final, ya que vamos a hacer el entrenamiento más informativo en el siguiente punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "MSw2j0btYWZs"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_acc(history, title=\"Model Accuracy\", ax=None):\n",
    "    \"\"\"Imprime una gráfica mostrando la accuracy por epoch obtenida en un entrenamiento\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1)        \n",
    "    ax.plot(history.history['acc'])\n",
    "    ax.plot(history.history['val_acc'])\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.legend(['Train', 'Val'], loc='upper left')\n",
    "    \n",
    "def plot_loss(history, title=\"Model Loss\", ax=None):\n",
    "    \"\"\"Imprime una gráfica mostrando la pérdida por epoch obtenida en un entrenamiento\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1)  \n",
    "    ax.plot(history.history['loss'])\n",
    "    ax.plot(history.history['val_loss'])\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.legend(['Train', 'Val'], loc='upper right')\n",
    "\n",
    "def plot_training(history):\n",
    "    # Print learning progress\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))  \n",
    "    plot_acc(history=history, ax=axs[0])\n",
    "    plot_loss(history=history, ax=axs[1])\n",
    "    fig.suptitle('Training Progress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "from keras import regularizers\n",
    "\n",
    "NUM_CLASSES = NUM_CHARS\n",
    "INPUT_SHAPE = X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 128)               64512     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 61)                7869      \n",
      "=================================================================\n",
      "Total params: 72,381\n",
      "Trainable params: 72,381\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Add early stopping and only storing the best model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=4, min_delta=0.02),\n",
    "             ModelCheckpoint('weights-best.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "            ]\n",
    "\n",
    "\n",
    "#regularizer=regularizers.l2(0.01)\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(len(word_index)+1, EMBEDDING_DIM, weights=[embedding_matrix], input_length=TEXT_LEN, trainable=False))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(64), input_shape=INPUT_SHAPE))\n",
    "#model.add(Dense(64, activation='relu', kernel_regularizer=regularizer))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/3\n",
      "80000/80000 [==============================] - 40s 494us/step - loss: 2.5650 - acc: 0.2711 - val_loss: 2.2446 - val_acc: 0.3281\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.32805, saving model to weights-best.hdf5\n",
      "Epoch 2/3\n",
      "80000/80000 [==============================] - 39s 492us/step - loss: 2.1631 - acc: 0.3480 - val_loss: 2.0972 - val_acc: 0.3543\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.32805 to 0.35430, saving model to weights-best.hdf5\n",
      "Epoch 3/3\n",
      "80000/80000 [==============================] - 39s 491us/step - loss: 2.0561 - acc: 0.3751 - val_loss: 2.0239 - val_acc: 0.3782\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.35430 to 0.37820, saving model to weights-best.hdf5\n",
      "CPU times: user 8min 49s, sys: 1min 55s, total: 10min 44s\n",
      "Wall time: 1min 59s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAFhCAYAAAAvP+0fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "%time history = model.fit(X, y, batch_size=64, epochs=3, verbose=1, validation_split=0.2, callbacks=callbacks)\n",
    "plot_training(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3yUFHS4kHkyY"
   },
   "source": [
    "Para ver cómo evoluciona nuestro modelo del lenguaje, vamos a generar texto según va entrenando. Para ello, vamos a programar una función que, utilizando el modelo en su estado actual, genere texto, con la idea de ver cómo se va generando texto al entrenar cada epoch.\n",
    "\n",
    "En el código de abajo podemos ver una función auxiliar para obtener valores de una distribución multinomial. Esta función se usará para muestrear el siguiente carácter a utilizar según las probabilidades de la salida de softmax (en vez de tomar directamente el valor con la máxima probabilidad, obtenemos un valor aleatorio según la distribución de probabilidad dada por softmax, de modo que nuestros resultados serán más diversos, pero seguirán teniendo \"sentido\" ya que el modelo tenderá a seleccionar valores con más probabilidad).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "LoGYpWOHd7Lr"
   },
   "outputs": [],
   "source": [
    "def sample(probs, temperature=1.0):\n",
    "    \"\"\"Nos da el índice del elemento a elegir según la distribución\n",
    "    de probabilidad dada por probs.\n",
    "    \n",
    "    Args:\n",
    "      probs es la salida dada por una capa softmax:\n",
    "        probs = model.predict(x_to_predict)[0]\n",
    "      \n",
    "      temperature es un parámetro que nos permite obtener mayor\n",
    "        \"diversidad\" a la hora de obtener resultados. \n",
    "        \n",
    "        temperature = 1 nos da la distribución normal de softmax\n",
    "        0 < temperature < 1 hace que el sampling sea más conservador,\n",
    "          de modo que sampleamos cosas de las que estamos más seguros\n",
    "        temperature > 1 hace que los samplings sean más atrevidos,\n",
    "          eligiendo en más ocasiones clases con baja probabilidad.\n",
    "          Con esto, tenemos mayor diversidad pero se cometen más\n",
    "          errores.\n",
    "    \"\"\"\n",
    "    # Cast a float64 por motivos numéricos\n",
    "    probs = np.asarray(probs).astype('float64')\n",
    "    \n",
    "    # Hacemos logaritmo de probabilidades y aplicamos reducción\n",
    "    # por temperatura.\n",
    "    probs = np.log(probs) / temperature\n",
    "    \n",
    "    # Volvemos a aplicar exponencial y normalizamos de nuevo\n",
    "    exp_probs = np.exp(probs)\n",
    "    probs = exp_probs / np.sum(exp_probs)\n",
    "    \n",
    "    # Hacemos el sampling dadas las nuevas probabilidades\n",
    "    # de salida (ver doc. de np.random.multinomial)\n",
    "    samples = np.random.multinomial(1, probs, 1)\n",
    "    maxidx = np.argmax(samples)\n",
    "    #return min(max(maxidx, 0), len(probs)-1)\n",
    "    return maxidx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3fejfZldd4ou"
   },
   "source": [
    "Utilizando la función anterior y el modelo entrenado, vamos a añadir un callback a nuestro modelo para que, según vaya entrenando, veamos los valores que resultan de generar textos con distintas temperaturas al acabar cada epoch.\n",
    "\n",
    "Para ello, abajo tenéis disponible el callback *on_epoch_end*. Esta función elige una secuencia de texto al azar en el texto disponible en la variable\n",
    "text y genera textos de longitud *GENERATED_TEXT_LENGTH* según las temperaturas en *TEMPERATURES_TO_TRY*, utilizando para ello la función *generate_text*.\n",
    "\n",
    "Completa la función *generate_text* de modo que utilicemos el modelo y la función sample para generar texto.\n",
    "\n",
    "NOTA: Cuando hagas model.predict, es aconsejable usar verbose=0 como argumento para evitar que la función imprima valores de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "xOEZvnBXkODd"
   },
   "outputs": [],
   "source": [
    "TEMPERATURES_TO_TRY = [0.2, 0.5, 1.0, 1.2]\n",
    "GENERATED_TEXT_LENGTH = 300\n",
    "\n",
    "def generate_text(seed_text, model, length, temperature=1):\n",
    "    \"\"\"Genera una secuencia de texto a partir de seed_text utilizando model.\n",
    "    \n",
    "    La secuencia tiene longitud length y el sampling se hace con la temperature\n",
    "    definida.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Aquí guardaremos nuestro texto generado, que incluirá el\n",
    "    # texto origen\n",
    "    generated = seed_text\n",
    "    \n",
    "    # Utilizar el modelo en un bucle de manera que generemos\n",
    "    # carácter a carácter. Habrá que construir los valores de\n",
    "    # X_pred de manera similar a como hemos hecho arriba, salvo que\n",
    "    # aquí sólo se necesita una oración\n",
    "    # Nótese que el x que utilicemos tiene que irse actualizando con\n",
    "    # los caracteres que se van generando. La secuencia de entrada al\n",
    "    # modelo tiene que ser una secuencia de tamaño SEQ_LENGTH que\n",
    "    # incluya el último caracter predicho.\n",
    " \n",
    "    ### TU CÓDIGO AQUÍ\n",
    "    generated = predict_text_bychar(generated, model, GENERATED_TEXT_LENGTH, char_one_hot_dict, index_char_dict)\n",
    "\n",
    "    ### FIN DE TU CÓDIGO\n",
    "    return generated\n",
    "\n",
    "\n",
    "\n",
    "def predict_text_bychar(seed_text, model, length, encoding, decoding):\n",
    "    generated = seed_text\n",
    "    N = len(seed_text)\n",
    "    for i in range(length):\n",
    "        text = generated[-N:]\n",
    "        enc_text = encode_text(text, encoding)\n",
    "        # Reshape encoded text, because model expects (X, SEQ_LENGTH, NUM_CARS)\n",
    "        enc_text = np.reshape(enc_text, (1,) + enc_text.shape)\n",
    "        prediction = model.predict(enc_text)\n",
    "        predicted_char = decoding[sample(prediction[0])]\n",
    "        generated += predicted_char\n",
    "    return generated\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "  print(\"\\n\\n\\n\")\n",
    "  \n",
    "  # Primero, seleccionamos una secuencia al azar para empezar a predecir\n",
    "  # a partir de ella\n",
    "  start_pos = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "  seed_text = text[start_pos:start_pos + SEQ_LENGTH]\n",
    "  for temperature in TEMPERATURES_TO_TRY:\n",
    "    print(\"------> Epoch: {} - Generando texto con temperature {}\".format(\n",
    "        epoch + 1, temperature))\n",
    "    \n",
    "    generated_text = generate_text(seed_text, model, \n",
    "                                   GENERATED_TEXT_LENGTH, temperature)\n",
    "    print(\"Seed: {}\".format(seed_text))\n",
    "    print(\"Texto generado: {}\".format(generated_text))\n",
    "    print()\n",
    "\n",
    "\n",
    "generation_callback = LambdaCallback(on_epoch_end=on_epoch_end)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BSMYZ2JdrSJg"
   },
   "source": [
    "Entrena ahora tu modelo. No te olvides de añadir *generation_callback* a la lista de callbacks utilizados en fit(). Ya que las métricas de clasificación no son tan críticas aquí (no nos importa tanto acertar el carácter exacto, sino obtener una distribución de probabilidad adecuada), no es necesario monitorizar la accuracy ni usar validation data, si bien puedes añadirlos para asegurarte de que todo está en orden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 39s 485us/step - loss: 1.8960 - acc: 0.4157 - val_loss: 1.8917 - val_acc: 0.4132\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.41320, saving model to weights-best.hdf5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 1 - Generando texto con temperature 0.2\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "20",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-31da6e016c64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time history = model.fit(X, y, batch_size=64, epochs=10, verbose=1, validation_split=0.2, callbacks=callbacks)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplot_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/manuel.pasieka/anaconda3/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/manuel.pasieka/anaconda3/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/manuel.pasieka/anaconda3/envs/py3/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/manuel.pasieka/anaconda3/envs/py3/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/manuel.pasieka/anaconda3/envs/py3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/manuel.pasieka/anaconda3/envs/py3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/manuel.pasieka/anaconda3/envs/py3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1253\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m                                 \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/manuel.pasieka/anaconda3/envs/py3/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-924588374ea7>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(epoch, logs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     generated_text = generate_text(seed_text, model, \n\u001b[0;32m---> 58\u001b[0;31m                                    GENERATED_TEXT_LENGTH, temperature)\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Seed: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Texto generado: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-924588374ea7>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(seed_text, model, length, temperature)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m### TU CÓDIGO AQUÍ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_text_bychar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGENERATED_TEXT_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_one_hot_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m### FIN DE TU CÓDIGO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-924588374ea7>\u001b[0m in \u001b[0;36mpredict_text_bychar\u001b[0;34m(seed_text, model, length, encoding)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0menc_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0menc_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mpredicted_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mgenerated\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpredicted_char\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 20"
     ]
    }
   ],
   "source": [
    "# Add early stopping and only storing the best model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=4, min_delta=0.02),\n",
    "             ModelCheckpoint('weights-best.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "             generation_callback,\n",
    "            ]\n",
    "\n",
    "model = model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "%time history = model.fit(X, y, batch_size=64, epochs=10, verbose=1, validation_split=0.2, callbacks=callbacks)\n",
    "\n",
    "plot_training(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en un lugar de la mancha, de chehoueaeoaeaovouoaooeurooaheeaoooueauhhuauoauiáeaeuouiamoieiiauauoeuehluoiaiouaooueuáuuuaaaeoetooeoa'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "predict_text(test[102:102+SEQ_LENGTH], model, 100, char_one_hot_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBbmz9DMhVhc"
   },
   "source": [
    "## Entregable\n",
    "\n",
    "Completa los apartados anteriores para entrenar modelos del lenguaje que sean capaces de generar texto con cierto sentido. Comentar los resultados obtenidos y cómo el modelo va mejorando época a época. Comentar las diferencias apreciadas al utilizar diferentes valores de temperatura. Entregar al menos la salida de un entrenamiento completo con los textos generados época a época.\n",
    "\n",
    "El objetivo no es conseguir generar pasajes literarios con coherencia, sino obtener lenguaje que se asemeje en cierta manera a lo visto en el texto original y donde las palabras sean reconocibles como construcciones en castellano. Como ejemplo de lo que se puede conseguir, este es el resultado de generar texto después de 10 epochs y con temperature 0.2:\n",
    "\n",
    "\n",
    "```\n",
    "-----> Epoch: 10 - Generando texto con temperature 0.2\n",
    "Seed: o le cautivaron y rindieron el\n",
    "Texto generado: o le cautivaron y rindieron el caballero de la caballería de la mano de la caballería del cual se le dijo:\n",
    "\n",
    "-¿quién es el verdad de la caballería de la caballería de la caballería de la caballería de la caballería, y me ha de habían de la mano que el caballero de la mano de la caballería. y que no se le habían de la mano de la c\n",
    "\n",
    "```\n",
    "\n",
    "Asimismo, se proponen los siguientes aspectos opcionales para conseguir nota extra:\n",
    "\n",
    "*   Experimentar con los textos de teatro en verso de Calderón de la Barca (¿es capaz el modelo de aprender las estructuras del teatro en verso?) o con alguno de los otros textos disponibles. También se puede probar con textos de vuestra elección.\n",
    "*   Experimentar con distintos valores de SEQ_LENGTH.\n",
    "*   Experimentar con los hiperparámetros del modelo o probar otro tipo de modelos como GRUs o *stacked* RNNs (RNNs apiladas).\n",
    "*   Experimentar utilizando embeddings en vez de representaciones one-hot.\n",
    "*   (Difícil) Entrenar un modelo secuencia a secuencia en vez de secuencia a carácter.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word based prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453904 words in total\n",
      "24135 unique words\n"
     ]
    }
   ],
   "source": [
    "def multi_replace(text, mapping):\n",
    "    \"\"\"\n",
    "    Replace occurences in text basedon mapping\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Generate something like: r'\\.|\\,|\\¿|\\?|\\!|\\;|\\-'\n",
    "    regexp = re.compile('|'.join(map(re.escape, mapping)))\n",
    "    \n",
    "    # Replace each occurence of a match string with its value\n",
    "    sub_sentences = regexp.sub(lambda match: mapping[match.group(0)], text)\n",
    "    \n",
    "    return sub_sentences\n",
    "\n",
    "# Generate a word index\n",
    "sentences = text.replace('\\n', ' ')\n",
    "\n",
    "special_chars = {'.':' <END>',\n",
    "           ',':' <COM>',\n",
    "           '¿':' <QUEST1>',\n",
    "           '?':' <QUEST2>',\n",
    "           '!':' <INDIC>',\n",
    "           ';': ' <SEMI>',\n",
    "           '-': ' <BAR> ',\n",
    "          }\n",
    "\n",
    "cleaned = multi_replace(sentences, special_chars)\n",
    "word_sequence = cleaned.split(' ')\n",
    "unique_words = set(word_sequence)\n",
    "print('%d words in total\\n%d unique words' % (len(word_sequence), len(unique_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get most common words\n",
    "word_freq_dict = {}\n",
    "for word in word_sequence:\n",
    "    cnt = word_freq_dict.get(word, 0)\n",
    "    word_freq_dict[word] = cnt+1\n",
    "\n",
    "# Remove '' spaces spaces?\n",
    "word_freq_dict.pop('')\n",
    "\n",
    "word_freq = [(v, k) for k, v in word_freq_dict.items()]\n",
    "word_freq = sorted(word_freq, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get 95% coverage of all word occurences in the text\n",
    "acc_threshold = len(word_sequence)*0.95\n",
    "\n",
    "N = 0\n",
    "word_list = []\n",
    "for n, w in word_freq:\n",
    "    N+=n\n",
    "    if N > acc_threshold:\n",
    "        break\n",
    "    word_list.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping 17662 words from the 24135 unique words\n"
     ]
    }
   ],
   "source": [
    "print('Keeping %d words from the %d unique words' % (len(word_list), len(unique_words)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_list.insert(0, '<UNKNOWN>')\n",
    "word_index = {w:i for i, w in enumerate(word_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_embedded(text, word_index, default=0):\n",
    "    \"\"\"\n",
    "    Helper function that encodes given text using encoding (like embedding)\n",
    "    \"\"\"\n",
    "    enc = []\n",
    "    for w in text:\n",
    "        enc.append(word_index.get(w, default))\n",
    "    return np.array(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emtext = text_embedded(word_sequence, word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,  3280,     2,  7916,     1,  8867,    17,    29,  2061,\n",
       "           1,  5043,     3, 14706,    13, 13240,     1, 17085,    13,\n",
       "        2771,     1,   153, 15629,     4,  2250,    13, 10687,     1,\n",
       "           0,    17,   185,   399,     4,    20,   729,     9,     8,\n",
       "        5526,   395,     0,  2429,     4, 12532,     1,  3234,     4,\n",
       "        8469,    34,    17,  2220,     1,    15,    48, 15615,     4,\n",
       "          18,   191,     1,     3,    13,   178,     4,     0,    14,\n",
       "        7344,    15,    20, 12525,     4,    18,    29,  3455,     9,\n",
       "         120,     7,    20,   130,    38,   574,     2,   675,     4,\n",
       "          13,  3522,     1,     3,    38,   644,     2,    11,  1119,\n",
       "           6,    13,   712,     1,     3,    31,   461,     4,   474,\n",
       "           3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emtext[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 453894 Sequences\n"
     ]
    }
   ],
   "source": [
    "# Definimos el tamaño de las secuencias. Puedes dejar este valor por defecto.\n",
    "SEQ_LENGTH = 10\n",
    "DICT_SIZE = len(word_index)\n",
    "\n",
    "sequences = []\n",
    "next_word = []\n",
    "\n",
    "# NOTE: is this a bug? But full_sequence has to be 31 of length, not 30!\n",
    "full_sequence = [emtext[i:i+j+1] for i in range(len(emtext)-SEQ_LENGTH) for j in range(SEQ_LENGTH,SEQ_LENGTH+1)]\n",
    "\n",
    "for sequence in full_sequence:\n",
    "    sequences.append(sequence[:-1])\n",
    "    next_word.append(sequence[-1])\n",
    "\n",
    "print('Generated %d Sequences' % (len(sequences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCES = len(sequences)\n",
    "MAX_SEQUENCES = 100000\n",
    "#MAX_SEQUENCES = 50000\n",
    "#MAX_SEQUENCES = 10000\n",
    "#MAX_SEQUENCES = 500\n",
    "\n",
    "perm = np.random.permutation(len(sequences))\n",
    "sequences_short, next_word_short = np.array(sequences), np.array(next_word)\n",
    "sequences_short, next_word_short = sequences_short[perm], next_word_short[perm]\n",
    "sequences_short, next_word_short = list(sequences_short[:MAX_SEQUENCES]), list(next_word_short[:MAX_SEQUENCES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate training data\n",
    "x_train = np.array(sequences_short)\n",
    "\n",
    "# One hot encode next_word\n",
    "y_train = np.zeros((MAX_SEQUENCES, DICT_SIZE))\n",
    "for i, w in enumerate(next_word_short):\n",
    "    y_train[i][w] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import LSTM, Bidirectional, Embedding\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 10, 100)           1766400   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               234496    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 17663)             4539391   \n",
      "=================================================================\n",
      "Total params: 6,540,287\n",
      "Trainable params: 6,540,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Add early stopping and only storing the best model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=4, min_delta=0.02),\n",
    "             ModelCheckpoint('weights-best.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "            ]\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index)+1, EMBEDDING_DIM, input_length=SEQ_LENGTH))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dense(len(word_index), activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEMPERATURES_TO_TRY = [0.2, 0.5, 1.0, 1.2]\n",
    "GENERATED_TEXT_LENGTH = 10\n",
    "\n",
    "def generate_text_byword(seed_text, model, length, temperature=1):\n",
    "    \"\"\"Genera una secuencia de texto a partir de seed_text utilizando model.\n",
    "    \n",
    "    La secuencia tiene longitud length y el sampling se hace con la temperature\n",
    "    definida.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Aquí guardaremos nuestro texto generado, que incluirá el\n",
    "    # texto origen\n",
    " \n",
    "    ### TU CÓDIGO AQUÍ\n",
    "    generated = predict_text_byword(seed_text, model, GENERATED_TEXT_LENGTH)\n",
    "\n",
    "    ### FIN DE TU CÓDIGO\n",
    "    decoded_text = ' '.join([word_list[i] for i in generated])\n",
    "    return decoded_text\n",
    "\n",
    "\n",
    "\n",
    "def predict_text_byword(seed_text, model, length):\n",
    "    generated = list(seed_text)\n",
    "    N = len(seed_text)\n",
    "    for i in range(length):\n",
    "        text = np.array(generated[-N:])\n",
    "        # Reshape encoded text, because model expects (X, SEQ_LENGTH, NUM_CARS)\n",
    "        text = np.reshape(text, (1,) + text.shape)\n",
    "        #print('Enter %s' % text)\n",
    "        prediction = model.predict(text)\n",
    "        predicted = sample(prediction[0])\n",
    "        #predicted = np.argmax(prediction[0])\n",
    "        #print('Predicted %d' % predicted)\n",
    "        generated.append(predicted)\n",
    "    return generated\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "  print(\"\\n\\n\\n\")\n",
    "  \n",
    "  # Primero, seleccionamos una secuencia al azar para empezar a predecir\n",
    "  # a partir de ella\n",
    "  start_pos = random.randint(0, len(emtext) - SEQ_LENGTH - 1)\n",
    "  seed_text = list(emtext[start_pos:start_pos + SEQ_LENGTH])\n",
    "  for temperature in TEMPERATURES_TO_TRY:\n",
    "    print(\"------> Epoch: {} - Generando texto con temperature {}\".format(\n",
    "        epoch + 1, temperature))\n",
    "    \n",
    "    generated_text = generate_text_byword(seed_text, model, \n",
    "                                   GENERATED_TEXT_LENGTH, temperature)\n",
    "    print(\"Seed: {}\".format(' '.join([word_list[i] for i in seed_text])))\n",
    "    print(\"Texto generado: {}\".format(generated_text))\n",
    "    print()\n",
    "\n",
    "\n",
    "generation_callback = LambdaCallback(on_epoch_end=on_epoch_end)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 249s 3ms/step - loss: 2.9912 - acc: 0.3849 - val_loss: 6.0894 - val_acc: 0.1573\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.15730, saving model to weights-best.hdf5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 1 - Generando texto con temperature 0.2\n",
      "Predicted 75\n",
      "Predicted 9\n",
      "Predicted 0\n",
      "Predicted 8\n",
      "Predicted 265\n",
      "Predicted 2\n",
      "Predicted 8\n",
      "Predicted 1303\n",
      "Predicted 354\n",
      "Predicted 60\n",
      "Seed: como ellas parecen <END> sobre un buen cimiento se puede\n",
      "Texto generado: como ellas parecen <END> sobre un buen cimiento se puede decir <END> <UNKNOWN> el entender que el médico ventero era\n",
      "\n",
      "------> Epoch: 1 - Generando texto con temperature 0.5\n",
      "Predicted 2731\n",
      "Predicted 2\n",
      "Predicted 346\n",
      "Predicted 108\n",
      "Predicted 12\n",
      "Predicted 38\n",
      "Predicted 1719\n",
      "Predicted 6\n",
      "Predicted 17\n",
      "Predicted 1102\n",
      "Seed: como ellas parecen <END> sobre un buen cimiento se puede\n",
      "Texto generado: como ellas parecen <END> sobre un buen cimiento se puede caber que palabras alguna <SEMI> una compañero a las alforjas\n",
      "\n",
      "------> Epoch: 1 - Generando texto con temperature 1.0\n",
      "Predicted 340\n",
      "Predicted 153\n",
      "Predicted 5204\n",
      "Predicted 3\n",
      "Predicted 2\n",
      "Predicted 6\n",
      "Predicted 265\n",
      "Predicted 40\n",
      "Predicted 1623\n",
      "Predicted 5607\n",
      "Seed: como ellas parecen <END> sobre un buen cimiento se puede\n",
      "Texto generado: como ellas parecen <END> sobre un buen cimiento se puede posible algún balcón y que a entender tan figuras prevención\n",
      "\n",
      "------> Epoch: 1 - Generando texto con temperature 1.2\n",
      "Predicted 12044\n",
      "Predicted 216\n",
      "Predicted 3\n",
      "Predicted 440\n",
      "Predicted 32\n",
      "Predicted 723\n",
      "Predicted 4\n",
      "Predicted 1032\n",
      "Predicted 1\n",
      "Predicted 35\n",
      "Seed: como ellas parecen <END> sobre un buen cimiento se puede\n",
      "Texto generado: como ellas parecen <END> sobre un buen cimiento se puede «la gusto y oro al aire de punta <COM> porque\n",
      "\n",
      "Epoch 2/10\n",
      "46400/80000 [================>.............] - ETA: 1:36 - loss: 2.3818 - acc: 0.4963"
     ]
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=4, min_delta=0.02),\n",
    "             ModelCheckpoint('weights-best.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "             generation_callback\n",
    "            ]\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "%time history = model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=1, validation_split=0.2, callbacks=callbacks)\n",
    "\n",
    "#test_loss, test_acc = model.evaluate(x_test_cut, y_test)\n",
    "#print('Test acc: %0.3f' % test_acc)\n",
    "\n",
    "plot_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[123, 11, 110]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "a.append(123)\n",
    "a.append(11)\n",
    "a.append(110)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 110]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-2:]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Lab 2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
